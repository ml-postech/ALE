# ğŸ§  Attribute-Leakage-Free Editing (ALE)

**Official Implementation of [Addressing Text Embedding Leakage in Diffusion-based Image Editing (ICCV 2025)]**

ALE is a *training-free* image editing framework that prevents attribute leakage in text-guided diffusion-based editing.  
It is accompanied by **ALE-Bench**, a benchmark for evaluating attribute leakage in multi-object text-based image editing.

<p align="center">
  <img src="figures/ale_compare.jpg" width="90%">
</p>
<p align="center">
  <em>ALE performs lakage-free edits guided by text prompts, while prior methods show attribute leakages.</em>
</p>

---

## ğŸ“ Project Structure

```
ale/                     # Core implementation of ALE
â”‚
â”œâ”€â”€ edit.py                  # Main editing pipeline
â”œâ”€â”€ pipeline_ead.py          # Diffusion pipeline for editing
â”œâ”€â”€ ore.py                   # Object-Restricted Embedding (ORE)
â”œâ”€â”€ rgb_cam.py               # Region-Guided Blending for Cross-Attention Masking (RGB-CAM)
â”œâ”€â”€ attention_control.py     # Background Blending (BB) and self-attention injection
â”œâ”€â”€ sam_utils.py             # SAM-based segmentation utilities
â”œâ”€â”€ config.py                # Configuration utilities
â”‚
ale_bench/               # ALE-Bench benchmark dataset
â”‚   â”œâ”€â”€ images/          # Source images
â”‚   â”œâ”€â”€ masks/           # Object masks (for evaluation)
â”‚   â””â”€â”€ prompts/         # Sourceâ€“target prompt pairs
â”‚
evaluate/                # Evaluation scripts
â”‚   â”œâ”€â”€ evaluate_ale.py       # Metric computation & statistics generation
â”‚   â””â”€â”€ metrics_calculator.py # Metric definitions (CLIP, PSNR, SSIM, LPIPS, etc.)
â”‚
outputs/                 # SAM outputs
results/                 # Edited outputs generated by ALE
stats/                   # Evaluation results (CSV + XLSX)
â”‚
ale_gradio.py            # Gradio demo interface
run_ale_bench.py         # Run ALE on ALE-Bench
README.md
.gitignore
```

---

## âš™ï¸ Installation

1ï¸âƒ£ Create the Conda environment
```bash
conda env create -f environment.yaml
```
2ï¸âƒ£ Install [Grounded SAM2]([https://github.com/facebookresearch/sam2](https://github.com/IDEA-Research/Grounded-SAM-2))

Follow the official [installation instructions](https://github.com/IDEA-Research/Grounded-SAM-2?tab=readme-ov-file#installation).

3ï¸âƒ£ Activate the environment
```bash
conda activate ale
```


---

## ğŸš€ Usage

### 1ï¸âƒ£ Run Gradio Demo

Launch the interactive editing interface:

```bash
python ./ale_gradio.py
```

This opens a **Gradio app** where you can:

* Load source images and masks
* Enter source and target prompts
* Perform localized, leakage-free text-guided editing

---

### 2ï¸âƒ£ Run ALE on ALE-Bench

Automatically perform batch editing on the benchmark dataset:

```bash
python ./run_ale_bench.py
```

This script:

* Loads images, prompts, and masks from `ale_bench/`
* Runs the ALE pipeline
* Saves generated results under `./results/`

---

### 3ï¸âƒ£ Evaluate Editing Results

Compute quantitative metrics and aggregate statistics:

```bash
python ./evaluate/evaluate_ale.py
```

This script:

* Loads edited results from `./results/`
* Computes metrics (TELS, TILS, Editing Performance, PSNR, SSIM, LPIPS, etc.)
* Saves:

  * `evaluation_results.csv`
  * Aggregated Excel summaries (`ale_mean_*.xlsx`)

All saved under the `./stats/` directory.

**Example output:**

```
stats/
â”œâ”€â”€ evaluation_results.csv
â”œâ”€â”€ ale_mean_per_target_count.xlsx
â”œâ”€â”€ ale_mean_per_edit_type.xlsx
â”œâ”€â”€ ale_mean_per_target_count_edit_type.xlsx
â””â”€â”€ ale_mean_all.xlsx
```

---

## ğŸ“Š Metrics Overview

| Metric                                       | Description                                                               | Direction                  |
| -------------------------------------------- | ------------------------------------------------------------------------- | -------------------------- |
| **TELS**                                     | Target-External Leakage Score â€” leakage into background/unrelated regions | Lower is better            |
| **TILS**                                     | Target-Internal Leakage Score â€” leakage between different edited objects  | Lower is better            |
| **Editing Performance**                      | CLIP-based alignment between target prompts and edited regions            | Higher is better           |
| **PSNR / SSIM / LPIPS / Structure Distance** | Standard image similarity metrics                                         | Higher / Lower accordingly |

---

## ğŸ¨ Results

<p align="center">
  <img src="figures/ale_results.jpg" width="90%">
</p>
<p align="center">
  <em>ALE achieves faithful, localized, and leakage-free edits guided by text prompts.</em>
</p>

<p align="center">
  <img src="figures/ale_table.png" width="90%">
</p>
<p align="center">
  <em>Qualitative comparison with existing editing methods.</em>
</p>


## ğŸ§© Citation

If you use **ALE** or **ALE-Bench**, please cite:

```bibtex
@InProceedings{mun2025ale,
    author    = {Mun, Sunung and Nam, Jinhwan and Cho, Sunghyun and Ok, Jungseul},
    title     = {Addressing Text Embedding Leakage in Diffusion-based Image Editing},
    booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},
    year      = {2025},
    url       = {https://arxiv.org/abs/2412.04715},
  }
```

---

## ğŸ“¬ Contact

**Sunung Mun**
POSTECH AI Graduate School
ğŸ“§ [mtablo@postech.ac.kr](mailto:mtablo@postech.ac.kr)


**Jinhwan Nam**
POSTECH AI Graduate School
ğŸ“§ [njh18@postech.ac.kr](njh18@postech.ac.kr)

---

### ğŸ™‡â€â™‚ï¸ Acknowledgements
This repository builds upon the open-source implementations of [InfEdit](https://github.com/sled-group/InfEdit) and [Prompt-to-Prompt](https://github.com/google/prompt-to-prompt).  

---

### ğŸ’¡ ALE: Making diffusion-based image editing **faithful**, **localized**, and **leakage-free**.

